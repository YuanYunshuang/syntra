# @package _global_

scratch:
  resolution: 384
  train_batch_size: 8
  num_train_workers: 4
  num_src: 3
  num_notions: 1
  num_tokens_per_notion: 4
  max_num_cls: 4
  base_lr: 1.0e-5
  vision_lr: 1.0e-5
  phases_per_epoch: 1
  num_iterations: 40000
  num_epochs: 400

dataset:
  name: SynTra
  root: /home/yuan/data/HisMap/syntra384
  split: paring_nshot100_intercls.json
  multiplier: 1

syntra:
  train_transforms:
    - _target_: training.dataset.transforms.ComposeAPI
      transforms:
        - _target_: training.dataset.transforms.RandomHorizontalFlip
          consistent_transform: True
        - _target_: training.dataset.transforms.RandomAffine
          degrees: 25
          shear: 5
          image_interpolation: bilinear
          consistent_transform: True
        - _target_: training.dataset.transforms.RandomResizeAPI
          sizes: ${scratch.resolution}
          square: true
          consistent_transform: True
        - _target_: training.dataset.transforms.ToTensorAPI
        - _target_: training.dataset.transforms.NormalizeAPI
          mean: [0.485, 0.456, 0.406]
          std: [0.229, 0.224, 0.225]

trainer:
  _target_: training.trainer.SingleGPUTrainer
  mode: train_only
  max_epochs: ${times:${scratch.num_epochs},${scratch.phases_per_epoch}}
  seed_value: 123
  # number of batches to accumulate gradients
  accumulate_grad_batches: 4

  model:
    _target_: training.model.syntra.SynTraTrain
    image_encoder:
      _target_: syntra.modeling.backbones.image_encoder.ImageEncoder
      scalp: 1
      trunk:
        _target_: syntra.modeling.backbones.hieradet.Hiera
        embed_dim: 112
        num_heads: 2
        drop_path_rate: 0.1
      neck:
        _target_: syntra.modeling.backbones.image_encoder.FpnNeck
        position_encoding:
          _target_: syntra.modeling.position_encoding.PositionEmbeddingSine
          num_pos_feats: 256
          normalize: true
          scale: null
          temperature: 10000
        d_model: 256
        backbone_channel_list: [896, 448, 224, 112]
        fpn_top_down_levels: [2, 3]  # output level 0 and 1 directly use the backbone features
        fpn_interp_model: nearest
    notion_attention:
      _target_: syntra.modeling.notion_attention.NotionAttention
      d_model: 256
      dim_feedforward: 2038
      num_sa_layers: 4
      num_ca_layers: 4
      pos_enc_at_attn: false
      pos_enc_at_cross_attn_keys: false
      pos_enc_at_cross_attn_queries: false
      activation: relu
      cross_attention:
        _target_: syntra.modeling.transformer.RoPEAttention
        rope_theta: 10000.0
        feat_sizes: [64, 64]
        rope_k_repeat: True
        embedding_dim: 256
        num_heads: 1
        downsample_rate: 1
        dropout: 0.1
        kv_in_dim: 256
      self_attention: 
        _target_: syntra.modeling.transformer.RoPEAttention
        rope_theta: 10000.0
        feat_sizes: [64, 64]
        embedding_dim: 256
        num_heads: 1
        downsample_rate: 1
        dropout: 0.1
    # input image resolution
    image_size: ${scratch.resolution}
    # dora rank for image encoder, dora_rank=0 means no dora
    dora_rank: 8
    # number of notions == number of masks predicted for each target image
    num_notions: ${scratch.num_notions}
    # whether to use high-resolution feature maps in the SAM mask decoder
    use_high_res_features: true
    # whether to use sigmoid to restrict ious prediction to [0-1]
    iou_prediction_use_sigmoid: true
    # Whether to predict if there is an object in the frame
    pred_obj_scores: true
    # Whether to use an MLP to predict object scores
    pred_obj_scores_mlp: true


  data:
    train:
      _target_: training.dataset.syntra_datasets.TorchTrainMixedDataset
      phases_per_epoch: ${scratch.phases_per_epoch}
      batch_sizes:
        - ${scratch.train_batch_size}
        - ${scratch.train_batch_size}
      auto_parse_datasets: ['donauwoerth.a', 'donauwoerth.b', 'hameln.a', 'hameln.b', 'siegfried.railway', 'siegfried.vineyard'] # all or a list of dataset names 
      multipliers: [1., 1., 1., 1., 1., 1.] #[1., 2., 0.2, 0.2, 0.16,   1.7]

      datasets:
        - _target_: training.dataset.utils.RepeatFactorWrapper
          dataset:
            _target_: training.dataset.utils.ConcatDataset
            datasets:
            - _target_: training.dataset.syntra_dataset.SynTraDataset
              transforms: ${syntra.train_transforms}
              notion_size: ${scratch.num_notions}
              training: true
              syntra_dataset:
                _target_: training.dataset.syntra_raw_dataset.PNGRawDataset
                root_folder: ${dataset.root}
                data_info_file: ${dataset.split}
              sampler:
                _target_: training.dataset.syntra_sampler.RandomUniformSampler
                num_src: ${scratch.num_src}
                max_num_cls: ${scratch.max_num_cls}
              multiplier: ${dataset.multiplier}

      shuffle: True
      num_workers: ${scratch.num_train_workers}
      pin_memory: True
      drop_last: True
      collate_fn:
        _target_: training.utils.data_utils.collate_fn
        _partial_: true
        dict_key: all
  
  optim:
    amp:
      enabled: True
      amp_dtype: bfloat16

    optimizer:
      _target_: torch.optim.AdamW
      weight_decay: 0.01

    # gradient_clip:
    #   _target_: training.optimizer.GradientClipper
    #   max_norm: 0.1
    #   norm_type: 2

    # param_group_modifiers:
    #   - _target_: training.optimizer.layer_decay_param_modifier
    #     _partial_: True
    #     layer_decay_value: 0.9
    #     apply_to: 'image_encoder.trunk'
    #     overrides:
    #       - pattern: '*pos_embed*'
    #         value: 1.0

    options:
      lr:
        - scheduler:
            _target_: fvcore.common.param_scheduler.CompositeParamScheduler
            schedulers:
              - _target_: fvcore.common.param_scheduler.LinearParamScheduler
                start_value: 1.0e-7
                end_value: ${scratch.base_lr}
              - _target_: fvcore.common.param_scheduler.CosineParamScheduler
                start_value: ${scratch.base_lr}
                end_value: ${divide:${scratch.base_lr},100}
            lengths: [0.1, 0.9]  # 10% warmup, 90% cosine decay
            interval_scaling: ['rescaled', 'rescaled']
        # - scheduler:
        #     _target_: fvcore.common.param_scheduler.CosineParamScheduler
        #     start_value: ${scratch.vision_lr}
        #     end_value: ${divide:${scratch.vision_lr},10}
        #   param_names:
        #     - 'image_encoder.*'
      # weight_decay:
      #   - scheduler:
      #       _target_: fvcore.common.param_scheduler.ConstantParamScheduler
      #       value: 0.01
      #   - scheduler:
      #       _target_: fvcore.common.param_scheduler.ConstantParamScheduler
      #       value: 0.01
      #     param_names:
      #       - '*bias*'
      #     module_cls_names: ['torch.nn.LayerNorm']

  loss:
    all:
      _target_: training.loss_fns.MultiStepMultiMasksAndIous
      weight_dict:
        loss_mask: 20
        loss_dice: 1
        loss_iou: 1
        loss_class: 0.1
      supervise_all_iou: true
      iou_use_l1_loss: true
      pred_obj_scores: true
      focal_gamma_obj_score: 0.0
      focal_alpha_obj_score: -1.0
      ce_loss: false

  logging:
    tensorboard_writer:
      _target_: training.utils.logger.make_tensorboard_logger
      log_dir:  ${launcher.experiment_log_dir}/tensorboard
      flush_secs: 120
      should_log: True
    log_dir: ${launcher.experiment_log_dir}/logs
    log_freq: 10
    log_visual_frequency: 50

  # initialize from a SAM 2 checkpoint
  checkpoint:
    save_dir: ${launcher.experiment_log_dir}/checkpoints
    save_freq: 0 # 0 only last checkpoint is saved.
    model_weight_initializer:
      _partial_: True
      _target_: training.utils.checkpoint_utils.load_sam2_img_encoder_to_syntra
      strict: True

      state_dict:
        _target_: training.utils.checkpoint_utils.load_checkpoint_and_apply_kernels
        checkpoint_path: ./checkpoints/sam2.1_hiera_base_plus.pt # PATH to SAM 2.1 checkpoint
        ckpt_state_dict_keys: ['model']

launcher:
  experiment_log_dir: null # Path to log directory, defaults to ./sam2_logs/${config_name}
  port_range: [10000, 65000]